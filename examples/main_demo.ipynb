{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MechIR Main Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/cchen207/git/brown/research/MechIR\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: mechir\n",
      "  Building wheel for mechir (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mechir: filename=mechir-0.0.1-py3-none-any.whl size=58998 sha256=378097fc0d016d9062f14a9fe1f04a43181835113bfd09e523053cf398fc7758\n",
      "  Stored in directory: /private/var/folders/w8/j9c1qwbx3cn8hf10x5nz_xtr0000gp/T/pip-ephem-wheel-cache-wugpaw_q/wheels/39/37/7c/9f04c1e8f880bc1e666f79cde17d9e585bcff18fdf2b5a9b0d\n",
      "Successfully built mechir\n",
      "Installing collected packages: mechir\n",
      "  Attempting uninstall: mechir\n",
      "    Found existing installation: mechir 0.0.1\n",
      "    Uninstalling mechir-0.0.1:\n",
      "      Successfully uninstalled mechir-0.0.1\n",
      "Successfully installed mechir-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformer_lens in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (0.34.2)\n",
      "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (0.14.1)\n",
      "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (0.0.3)\n",
      "Requirement already satisfied: datasets>=2.7.1 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (3.0.1)\n",
      "Requirement already satisfied: einops>=0.6.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (0.8.0)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (0.0.3)\n",
      "Requirement already satisfied: jaxtyping>=0.2.11 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (0.2.34)\n",
      "Requirement already satisfied: numpy>=1.26 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (2.1.1)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (2.2.3)\n",
      "Requirement already satisfied: rich>=12.6.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (13.9.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (0.2.0)\n",
      "Requirement already satisfied: torch!=2.0,!=2.1.0,>=1.10 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (2.4.1)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (4.66.5)\n",
      "Requirement already satisfied: transformers>=4.37.2 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (4.45.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (4.12.2)\n",
      "Requirement already satisfied: wandb>=0.13.5 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformer_lens) (0.18.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (0.25.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from accelerate>=0.23.0->transformer_lens) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from datasets>=2.7.1->transformer_lens) (3.10.8)\n",
      "Requirement already satisfied: typeguard==2.13.3 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from jaxtyping>=0.2.11->transformer_lens) (2.13.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from pandas>=1.1.5->transformer_lens) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from rich>=12.6.0->transformer_lens) (2.18.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (75.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformers>=4.37.2->transformer_lens) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from transformers>=4.37.2->transformer_lens) (0.20.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (5.28.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (2.15.0)\n",
      "Requirement already satisfied: setproctitle in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from wandb>=0.13.5->transformer_lens) (1.3.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.13.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.11)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from jinja2->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from sympy->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/anaconda3/envs/mechir/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ..\n",
    "%pip install transformer_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mechir/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mechir import Dot, MechIRDataset, DotDataCollator\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Support for BERT in TransformerLens is currently experimental, until such a time when it has feature parity with HookedTransformer and has been tested on real research tasks. Until then, backward compatibility is not guaranteed. Please see the docs for information on the limitations of the current implementation.\n",
      "If using BERT for interpretability research, keep in mind that BERT has some significant architectural differences to GPT. For example, LayerNorms are applied *after* the attention and MLP components, meaning that the last LayerNorm in a block cannot be folded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "Loaded pretrained model sebastian-hofstaetter/distilbert-dot-tas_b-b256-msmarco into HookedEncoder\n"
     ]
    }
   ],
   "source": [
    "model = Dot(\"sebastian-hofstaetter/distilbert-dot-tas_b-b256-msmarco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1239</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1502</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4462</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4569</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id doc_id  relevance iteration\n",
       "0        1   1239          1         0\n",
       "1        1   1502          1         0\n",
       "2        1   4462          1         0\n",
       "3        1   4569          1         0\n",
       "4        1   5472          1         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load smallest dataset for quick testing\n",
    "dataset = MechIRDataset(\"vaswani\")\n",
    "dataset.pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries in dataset: 93\n",
      "\n",
      "----------- Examples of queries: -----------\n",
      "\n",
      "MEASUREMENT OF DIELECTRIC CONSTANT OF LIQUIDS BY THE USE OF MICROWAVE TECHNIQUES\n",
      "\n",
      "MATHEMATICAL ANALYSIS AND DESIGN DETAILS OF WAVEGUIDE FED MICROWAVE RADIATIONS\n",
      "\n",
      "USE OF DIGITAL COMPUTERS IN THE DESIGN OF BAND PASS FILTERS HAVING GIVEN PHASE AND ATTENUATION CHARACTERISTICS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print examples of queries\n",
    "print(\"Total queries in dataset:\", len(dataset.queries.items()))\n",
    "print(\"\\n----------- Examples of queries: -----------\\n\")\n",
    "example_queries = list(dataset.queries.values())[:3]\n",
    "for query in example_queries:\n",
    "    print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in dataset: 11429\n",
      "Minimum Length (in words): 2\n",
      "Maximum Length (in words): 269\n",
      "Average Length (in words): 41.93\n",
      "\n",
      "----------- Examples of documents: -----------\n",
      "\n",
      "compact memories have flexible capacities  a digital data storage\n",
      "system with capacity up to bits and random and or sequential access\n",
      "is described\n",
      "\n",
      "an electronic analogue computer for solving systems of linear equations\n",
      "mathematical derivation of the operating principle and stability\n",
      "conditions for a computer consisting of amplifiers\n",
      "\n",
      "electronic coordinate transformer  circuit details are given for\n",
      "the construction of an electronic calculating unit which enables\n",
      "the polar coordinates of a vector modulus and cosine or sine of the\n",
      "argument to be derived from those of a rectangular system of axes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate document stats\n",
    "doc_lengths = [len(doc.split()) for doc in dataset.docs.values()]\n",
    "\n",
    "# Print examples of documents\n",
    "print(\"Total documents in dataset:\", len(dataset.docs.items()))\n",
    "print(f\"Minimum Length (in words): {min(doc_lengths)}\")\n",
    "print(f\"Maximum Length (in words): {max(doc_lengths)}\")\n",
    "print(f\"Average Length (in words): {(sum(doc_lengths) / len(doc_lengths) if doc_lengths else 0):.2f}\")\n",
    "print(\"\\n----------- Examples of documents: -----------\\n\")\n",
    "example_docs = list(dataset.docs.values())[:3]\n",
    "for doc in example_docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: MEASUREMENT OF DIELECTRIC CONSTANT OF LIQUIDS BY THE USE OF MICROWAVE TECHNIQUES\n",
      "\n",
      "-------------------------------\n",
      "Document:\n",
      "broadband millimetre wave paramagnetic resonance spectrometer  the\n",
      "specimen and waveguide which can be cooled by means of a cryostat\n",
      "are placed between close pole pieces giving high uniform magnetic\n",
      "fields  design details and some measurements on zero field splittings\n",
      "are given\n",
      "\n",
      "Document:\n",
      "microwave measurements of dielectric absorption in dilute solutions\n",
      "\n",
      "Document:\n",
      "dielectric properties of ice at very low frequencies and the influence\n",
      "of a polarizing field  measurements at frequencies down to are reported\n",
      "the loss factor passes through a low frequency maximum which is distinguishable\n",
      "from that associated with the dipole dispersion by its different\n",
      "temperature dependence  the effect of impurities is to shift the\n",
      "maximum towards higher frequencies  application of a unidirectional\n",
      "field does not affect the permittivity of the pure crystals but eliminates\n",
      "the low frequency dispersion when impurities are present  the\n",
      "observations are consistent with macdonalds theory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print example of one query and relevant documents\n",
    "query_rel_doc_ex_df = dataset.pairs.head(3)[[\"query_id\", \"doc_id\"]]\n",
    "query_id = query_rel_doc_ex_df[\"query_id\"].unique()[0]\n",
    "doc_ids = query_rel_doc_ex_df[\"doc_id\"]\n",
    "print(f\"Query: {dataset.queries[query_id]}\")\n",
    "print(\"-------------------------------\")\n",
    "for doc_id in doc_ids:\n",
    "    print(f\"Document:\\n{dataset.docs[doc_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip newlines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Paired Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define perturbation (for now just test simple append static term, later test TF/IDF)\n",
    "# from mechir.perturb import perturbation # can't get import to work rn\n",
    "def append_term(text, query=None):\n",
    "    return text + \"apple banana orange\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['[X]']}\n",
      "30522\n"
     ]
    }
   ],
   "source": [
    "model.tokenizer.add_special_tokens({\"additional_special_tokens\": [\"[X]\"]})\n",
    "print(model.tokenizer.special_tokens_map)\n",
    "print(model.tokenizer.convert_tokens_to_ids('[X]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "data_collator = DotDataCollator(model.tokenizer, append_term)\n",
    "dataloader = DataLoader(dataset, batch_size=2, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function just to print\n",
    "def pretty_print_triplets(batch, tokenizer):\n",
    "    \"\"\"\n",
    "    Pretty prints triplets of queries, documents, and their corresponding perturbed documents from a batch.\n",
    "\n",
    "    Args:\n",
    "        batch (dict): A dictionary containing 'queries', 'documents', and 'perturbed_documents' from a DataLoader.\n",
    "        tokenizer: The tokenizer used to decode the input IDs.\n",
    "    \"\"\"\n",
    "    # Get the queries, documents, and perturbed documents from the batch\n",
    "    queries = batch[\"queries\"]\n",
    "    documents = batch[\"documents\"]\n",
    "    perturbed_documents = batch[\"perturbed_documents\"]\n",
    "\n",
    "    # Loop through the batch size\n",
    "    for doc_id in range(len(documents[\"input_ids\"])):\n",
    "        # Get the input IDs\n",
    "        query_ids = queries[\"input_ids\"][doc_id]\n",
    "        original_doc_ids = documents[\"input_ids\"][doc_id]\n",
    "        perturbed_doc_ids = perturbed_documents[\"input_ids\"][doc_id]\n",
    "\n",
    "        # Decode the input IDs to text\n",
    "        query_decoded = tokenizer.decode(query_ids.tolist(), skip_special_tokens=False)\n",
    "        original_doc_decoded = tokenizer.decode(original_doc_ids.tolist(), skip_special_tokens=False)\n",
    "        perturbed_doc_decoded = tokenizer.decode(perturbed_doc_ids.tolist(), skip_special_tokens=False)\n",
    "\n",
    "        # Pretty print\n",
    "        print(f\"Triplet {doc_id + 1}:\")\n",
    "        print(\"Query (Decoded):\", query_decoded)\n",
    "        print(\"Original Document (Decoded):\", original_doc_decoded)\n",
    "        print(\"Perturbed Document (Decoded):\", perturbed_doc_decoded)\n",
    "        print(\"=\" * 50)  # Separator for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet 1:\n",
      "Query (Decoded): [CLS] measurement of dielectric constant of liquids by the use of microwave techniques [SEP]\n",
      "Original Document (Decoded): [CLS] broadband millimetre wave paramagnetic resonance spectrometer the specimen and waveguide which can be cooled by means of a cryostat are placed between close pole pieces giving high uniform magnetic fields design details and some measurements on zero field splittings are given [X] [X] [X] [SEP]\n",
      "Perturbed Document (Decoded): [CLS] broadband millimetre wave paramagnetic resonance spectrometer the specimen and waveguide which can be cooled by means of a cryostat are placed between close pole pieces giving high uniform magnetic fields design details and some measurements on zero field splittings are given apple banana orange [SEP]\n",
      "==================================================\n",
      "Triplet 1:\n",
      "Query (Decoded): [CLS] measurement of dielectric constant of liquids by the use of microwave techniques [SEP]\n",
      "Original Document (Decoded): [CLS] microwave measurements of dielectric absorption in dilute solutions [X] [X] [X] [SEP]\n",
      "Perturbed Document (Decoded): [CLS] microwave measurements of dielectric absorption in dilute solutions apple banana orange [SEP]\n",
      "==================================================\n",
      "Triplet 1:\n",
      "Query (Decoded): [CLS] measurement of dielectric constant of liquids by the use of microwave techniques [SEP]\n",
      "Original Document (Decoded): [CLS] dielectric properties of ice at very low frequencies and the influence of a polarizing field measurements at frequencies down to are reported the loss factor passes through a low frequency maximum which is distinguishable from that associated with the dipole dispersion by its different temperature dependence the effect of impurities is to shift the maximum towards higher frequencies application of a unidirectional field does not affect the permittivity of the pure crystals but eliminates the low frequency dispersion when impurities are present the observations are consistent with macdonalds theory [X] [X] [X] [SEP]\n",
      "Perturbed Document (Decoded): [CLS] dielectric properties of ice at very low frequencies and the influence of a polarizing field measurements at frequencies down to are reported the loss factor passes through a low frequency maximum which is distinguishable from that associated with the dipole dispersion by its different temperature dependence the effect of impurities is to shift the maximum towards higher frequencies application of a unidirectional field does not affect the permittivity of the pure crystals but eliminates the low frequency dispersion when impurities are present the observations are consistent with macdonalds theory apple banana orange [SEP]\n",
      "==================================================\n",
      "Triplet 1:\n",
      "Query (Decoded): [CLS] measurement of dielectric constant of liquids by the use of microwave techniques [SEP]\n",
      "Original Document (Decoded): [CLS] transmission of electromagnetic waves through inhomogeneous layers layers are considered in which the dielectric constant is graded from the value unity at each face to a maximum value at the mid plane the variation being either linear or exponential dielectrics are prepared satisfying this specification by forming ordinary homogeneous materials into a series of wedges or the like thus producing a space periodic structure reflection factor measurements made in free space and in waveguides are reported variation of reflection factor with layer thickness is shown graphically for moltopren paraffin and trolitul variation with angle of incidence is shown for trolitul the experimental results are compared with values of the reflection factor calculated from solutions of maxwells equations for the appropriate conditions such structures can give good transmission of microwaves over a wide frequency band [X] [X] [X] [SEP]\n",
      "Perturbed Document (Decoded): [CLS] transmission of electromagnetic waves through inhomogeneous layers layers are considered in which the dielectric constant is graded from the value unity at each face to a maximum value at the mid plane the variation being either linear or exponential dielectrics are prepared satisfying this specification by forming ordinary homogeneous materials into a series of wedges or the like thus producing a space periodic structure reflection factor measurements made in free space and in waveguides are reported variation of reflection factor with layer thickness is shown graphically for moltopren paraffin and trolitul variation with angle of incidence is shown for trolitul the experimental results are compared with values of the reflection factor calculated from solutions of maxwells equations for the appropriate conditions such structures can give good transmission of microwaves over a wide frequency band apple banana orange [SEP]\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mechir/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2855: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataloader):\n",
    "    pretty_print_triplets(batch, model.tokenizer)\n",
    "\n",
    "    # stop after 2 batches\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Difference in Performance on Perturbed Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Patching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Attention Heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Tokens (by position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Attention Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mechir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
